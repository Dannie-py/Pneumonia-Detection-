{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "mount_file_id": "15u7HDp3cQ-Upx52jUlxjxs8pwCtoNpUX",
      "authorship_tag": "ABX9TyN2UBKB2zHKXgpVgrmJ784M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dannie-py/Pneumonia-Detection-/blob/main/Pneumonia_DetectionPro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount GitHub Reprository"
      ],
      "metadata": {
        "id": "Fwir6UvWi0Uh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sov7uFzUh6Ub",
        "outputId": "b6326ae2-87ce-4c6a-babf-ff4cb5db0690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repository'...\n",
            "remote: Repository not found.\n",
            "fatal: repository 'https://github.com/Dannie-py/repository.git/' not found\n"
          ]
        }
      ],
      "source": [
        "!git clone https://Dannie-py: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@github.com/Dannie-py/repository.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dannie-py/Pneumonia-Detection-/repository.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2OTzMd4qoG2",
        "outputId": "fa567135-4a9e-4388-ebee-e4271ecaaa1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repository'...\n",
            "remote: Not Found\n",
            "fatal: repository 'https://github.com/Dannie-py/Pneumonia-Detection-/repository.git/' not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dannie-Proj/COVID-Classification.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz4zDzutyQjQ",
        "outputId": "269cc40b-f5d6-473f-8b43-00438aabb650"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COVID-Classification'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 28 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (28/28), 10.92 KiB | 10.92 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd repository\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rg7ESBHpAoz",
        "outputId": "01d4933e-5a08-4a1b-8f48-08dbe8bc2034"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'repository'\n",
            "/content\n",
            "COVID-Classification  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Pneumonia-Detection-\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNKfttdVyZV2",
        "outputId": "24ea6fdc-54e7-4f12-bec8-960fd6ca7377",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Pneumonia-Detection-'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0P8nDvMyrtn",
        "outputId": "aaa299fc-b6df-49e7-f205-079e6069f4e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COVID-Classification  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup and Install Dependencies"
      ],
      "metadata": {
        "id": "8sMhFYhu5zpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installs TensorFlow and Keras (deep learning libraries) Needed to define, train, and evaluate CNN models."
      ],
      "metadata": {
        "id": "TloKG0se5-ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow"
      ],
      "metadata": {
        "id": "DZB66eNr47EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "metadata": {
        "id": "sZWbmvrU5Son"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-addons"
      ],
      "metadata": {
        "id": "kBCyY8OR5tZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b58ead66-75f5-405e-8a25-966b45b2e6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries Brings in model-building tools, layers, and image utilities for preprocessing and training."
      ],
      "metadata": {
        "id": "HJpOvtR673N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "import numpy as np # for numerical operations\n",
        "import tensorflow as tf # tensorflow framework\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D # for building models\n",
        "from tensorflow.keras.models import Model # for building models\n",
        "from tensorflow.keras import layers, models # for building models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # for data augmentation\n",
        "from tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB0, MobileNetV2, InceptionV3  # imports pretrained models\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "import cv2 #for image processing\n",
        "import os # for path operations\n",
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix # evaluation metrics\n",
        "from fpdf import FPDF # for creating pdf reports\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vZIGWPLrV47",
        "outputId": "ef629d75-796e-4d28-9110-0913a4aac4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting the dataset into Train, Val and Test data"
      ],
      "metadata": {
        "id": "o9bUC2oCDbX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules for file operations and data splitting\n",
        "import os, shutil\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "So3v2ah_EiHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# split whole dataset into percentages of Train:70%, Val:15% and Test:15%"
      ],
      "metadata": {
        "id": "mDhKoON0FRr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original dataset folder\n",
        "original_dataset_dir = '/content/drive/MyDrive/Colab Notebooks/Data/images'\n",
        "\n",
        "target_base_dir = '/content/drive/MyDrive/Colab Notebooks/Data/images'\n",
        "classes = ['COVID', 'Normal', 'Viral Pneumonia']\n",
        "\n",
        "# Create target folders\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for cls in classes:\n",
        "        os.makedirs(os.path.join(target_base_dir, split, cls), exist_ok=True)\n",
        "\n",
        "# Split and copy images\n",
        "for cls in classes:\n",
        "    src_dir = os.path.join(original_dataset_dir, cls)\n",
        "    images = os.listdir(src_dir)\n",
        "    train, temp = train_test_split(images, test_size=0.3, random_state=42)\n",
        "    val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    for img in train:\n",
        "        shutil.copy(os.path.join(src_dir, img), os.path.join(target_base_dir, 'train', cls, img))\n",
        "    for img in val:\n",
        "        shutil.copy(os.path.join(src_dir, img), os.path.join(target_base_dir, 'val', cls, img))\n",
        "    for img in test:\n",
        "        shutil.copy(os.path.join(src_dir, img), os.path.join(target_base_dir, 'test', cls, img))"
      ],
      "metadata": {
        "id": "47zx9CqbFbDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image data generators to Rescale image pixel values, Augments images (e.g., flipping, zooming) to reduce overfitting and creates batches of images for training/validation."
      ],
      "metadata": {
        "id": "vP5nTVRXr6cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google drive can be mounted with the follwoing codes if not using the mounting icon on the file browser on the left.\n",
        "#from google.colab import drive # to mount google drive.\n",
        "#drive.mount('/content/drive/MyDrive/Colab Notebooks/Data/images') # mount Google Drive to access the dataset\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/Data/images\" # setting the dataset path\n",
        "\n",
        "# Image preprocessing\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "num_classes = 3\n",
        "class_names = ['COVID', 'Normal', 'Viral Pneumonia']\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'train'),\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'val'),\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    target_size=img_size,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False # ensures order of prediction matches filenames\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gozDeKQRr_OM",
        "outputId": "f0e26f8e-7ec7-4d1f-ec7e-d830386cec60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10606 images belonging to 4 classes.\n",
            "Found 2273 images belonging to 4 classes.\n",
            "Found 2274 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a function to build models by the use of transfer learning (feature extraction)"
      ],
      "metadata": {
        "id": "ctEOHvgLTi9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(model_name, input_shape=(224,224,3), num_classes=3):\n",
        "  # convert model name to lowercase for comparison of case-sensitivity\n",
        "  base_model_name = base_model_name.lower()\n",
        "  base_model = None # for base model placeholder\n",
        "\n",
        "  # loading the base model with pretrained ImageNet weights, excluding the top layers\n",
        "  if base_model_name == 'resnet50':\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "  elif base_model_name == 'densenet121':\n",
        "    from tensorflow.keras.applications import DenseNet121\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "  elif base_model_name == 'efficientnetb0':\n",
        "    from tensorflow.keras.applications import EfficientNetB0\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "  elif base_model_name == 'mobilenetv2':\n",
        "    from tensorflow.keras.applications import MobileNetV2\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "  elif base_model_name == 'inceptionv3':\n",
        "    from tensorflow.keras.applications import InceptionV3\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "  else:\n",
        "    raise ValueError(\"Invalid base model name. Supported models are 'resnet50', 'densenet121', 'efficientnetb0', 'mobilenetv2', and 'inceptionv3'.\") # raise an error when a different model is used. unknown model name not valid\n",
        "\n",
        "    # freezing base model to avoid its weights been updated whiles traing\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # include custom layers on top of the base model\n",
        "    x = base_model.output # getting base model output\n",
        "    x = GlobalAveragePooling2D()(x) # add global average pooling layer to reduce feature maps\n",
        "    output = Dense(num_classes, activation='softmax')(x) # add a dense output layer with softmax activation for classification\n",
        "\n",
        "    # create the model\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    # compile the models using Adam optimizer and categorical crossentropy loss\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy']) # this will track accuracy during training\n",
        "\n",
        "    return model # compiled model is returned\n",
        "\n"
      ],
      "metadata": {
        "id": "MbeSKM_gT4_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to train the models"
      ],
      "metadata": {
        "id": "6eCnQ5osdIPT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c24skaxZdSdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to evaluate the models"
      ],
      "metadata": {
        "id": "R4MduXR_dTBT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LqnZLEodbpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to plot training curves"
      ],
      "metadata": {
        "id": "ZSW19Zp9dcqi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EmFAuBREdvrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRAD-CAM VISUALIZATION - function for Grad-CAM assist"
      ],
      "metadata": {
        "id": "JYEr9YcAdwVl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3UVoXWrd6W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to generate Grad-CAM for the sample images"
      ],
      "metadata": {
        "id": "arGps-53eDIW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "je7Fp70heOSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate PDF report"
      ],
      "metadata": {
        "id": "Le1crydFg1kL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Uo3gCb9hO8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}